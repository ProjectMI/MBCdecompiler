"""Instruction listing utilities."""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Sequence, TYPE_CHECKING

from .analyzer import PipelineAnalyzer
from .analyzer.instruction_profile import InstructionKind, resolve_opcode_info
from .instruction import InstructionWord, read_instructions
from .ir import build_segment_ir
from .knowledge import KnowledgeBase
from .mbc import MbcContainer, Segment


if TYPE_CHECKING:  # pragma: no cover - type checking helper
    from .analyzer.report import PipelineReport


@dataclass
class ListingSummary:
    """Aggregated overview of unknown pipeline analysis results."""

    unknown_kinds: int = 0
    unknown_categories: int = 0
    unknown_patterns: int = 0
    unknown_dominant: int = 0
    warning_count: int = 0

    def observe_report(self, report: "PipelineReport") -> None:
        """Update counters using the supplied pipeline ``report``."""

        self.warning_count += len(report.warnings)

        for block in report.blocks:
            if block.kind is InstructionKind.UNKNOWN:
                self.unknown_kinds += 1
            if block.category == "unknown":
                self.unknown_categories += 1
            if block.pattern is None:
                self.unknown_patterns += 1

        statistics = report.statistics
        if statistics is None:
            self.unknown_dominant += 1
        else:
            dominant = statistics.dominant_category()
            if dominant is None or dominant == "unknown":
                self.unknown_dominant += 1


class Disassembler:
    """Render textual disassembly listings enriched with pipeline analysis."""

    def __init__(
        self,
        knowledge: KnowledgeBase,
        *,
        analyzer: Optional[PipelineAnalyzer] = None,
    ) -> None:
        self.knowledge = knowledge
        self.analyzer = analyzer or PipelineAnalyzer(knowledge)
        self._summary: Optional[ListingSummary] = None

    def generate_listing(
        self,
        container: MbcContainer,
        *,
        segment_indices: Optional[Sequence[int]] = None,
        max_instructions: Optional[int] = None,
    ) -> str:
        selection = tuple(segment_indices or [])
        lines: List[str] = []
        self._summary = ListingSummary()
        summary = self._summary

        if selection:
            segment_map = {segment.index: segment for segment in container.segments()}
            for index in selection:
                segment = segment_map.get(index)
                if segment is None:
                    continue
                lines.extend(self._render_segment(segment, max_instructions, summary))
        else:
            for segment in container.segments():
                lines.extend(self._render_segment(segment, max_instructions, summary))
        return "\n".join(lines) + "\n"

    @property
    def summary(self) -> Optional[ListingSummary]:
        """Return the summary generated by the most recent listing run."""

        return self._summary

    def _render_segment(
        self,
        segment: Segment,
        max_instructions: Optional[int],
        summary: Optional[ListingSummary],
    ) -> List[str]:
        instructions, remainder = read_instructions(segment.data, segment.start)
        report = self.analyzer.analyse_segment(instructions) if self.analyzer else None

        if report and summary:
            summary.observe_report(report)

        header = (
            f"; segment {segment.index} offset=0x{segment.start:06X} length={segment.length}"
        )
        lines = [header]

        if report and report.statistics:
            stats = report.statistics
            dominant = stats.dominant_category() or "n/a"
            recognised = stats.recognised_ratio()
            lines.append(
                "; pipeline stats: blocks={blocks} instructions={instr} stackÎ”={delta:+d} dominant={dominant} recognised={recognised:.2f}".format(
                    blocks=stats.block_count,
                    instr=stats.instruction_count,
                    delta=stats.total_stack_delta,
                    dominant=dominant,
                    recognised=recognised,
                )
            )
        if report and report.warnings:
            lines.append("; pipeline warnings:")
            for warning in report.warnings:
                lines.append(f";   - {warning}")

        block_map = self._index_blocks(report.blocks) if report else {}

        for idx, instruction in enumerate(instructions):
            block_lines = block_map.get(instruction.offset)
            if block_lines:
                lines.extend(block_lines)
            if max_instructions is not None and idx >= max_instructions:
                lines.append("; ... truncated ...")
                break
            lines.append(self._format_instruction(instruction))
        if remainder:
            lines.append(f"; trailing {remainder} byte(s) ignored")
        lines.append("")
        return lines

    def _format_instruction(self, instruction: InstructionWord) -> str:
        key = instruction.label()
        info, heuristic = resolve_opcode_info(instruction, self.knowledge)

        mnemonic = info.mnemonic if info else f"op_{instruction.opcode:02X}_{instruction.mode:02X}"
        summary = ""
        if info and info.summary:
            summary = f" ; {info.summary}"
            if heuristic:
                summary += " (heuristic)"
        elif heuristic:
            summary = " ; heuristic"

        return (
            f"{instruction.offset:08X}: {instruction.raw:08X}    "
            f"{mnemonic:<24} op={instruction.opcode:02X} "
            f"mode={instruction.mode:02X} operand=0x{instruction.operand:04X}{summary}"
        )

    def _index_blocks(
        self, blocks: Sequence["PipelineBlock"]
    ) -> Dict[int, List[str]]:
        from .analyzer.report import PipelineBlock  # local import to avoid cycle

        indexed: Dict[int, List[str]] = {}
        for idx, block in enumerate(blocks):
            if not block.profiles:
                continue
            start_offset = block.profiles[0].word.offset
            indexed[start_offset] = self._format_block(idx, block)
        return indexed

    def _format_block(self, index: int, block: "PipelineBlock") -> List[str]:
        from .analyzer.report import PipelineBlock  # local import to avoid cycle

        pattern = block.pattern.pattern.name if block.pattern else "?"
        header = (
            f"; pipeline block {index + 1}: [{block.start_offset:08X}-{block.end_offset:08X}] "
            f"kind={block.kind.name} category={block.category} {block.stack.describe()} "
            f"len={len(block.profiles)} pattern={pattern} conf={block.confidence:.2f}"
        )
        lines = [header]
        note_lines = self._format_block_notes(block.notes)
        lines.extend(note_lines)
        return lines

    @staticmethod
    def _format_block_notes(notes: Iterable[str]) -> List[str]:
        formatted: List[str] = []
        for note in notes:
            message = note.strip()
            if not message:
                continue
            formatted.append(f";   note: {message}")
        return formatted

    def write_listing(
        self,
        container: MbcContainer,
        output_path: Path,
        *,
        segment_indices: Optional[Sequence[int]] = None,
        max_instructions: Optional[int] = None,
    ) -> Optional[ListingSummary]:
        listing = self.generate_listing(
            container,
            segment_indices=segment_indices,
            max_instructions=max_instructions,
        )
        output_path.write_text(listing, "utf-8")
        return self._summary

    # ------------------------------------------------------------------
    # IR generation helpers
    # ------------------------------------------------------------------

    def generate_ir(
        self,
        container: MbcContainer,
        *,
        segment_indices: Optional[Sequence[int]] = None,
        max_instructions: Optional[int] = None,
    ) -> str:
        """Return the normalised IR for ``container`` as a textual dump."""

        lines: List[str] = []
        selection = tuple(segment_indices or [])

        def _emit_segment(segment: Segment) -> None:
            instructions, _ = read_instructions(segment.data, segment.start)
            if max_instructions is not None:
                instructions = instructions[:max_instructions]
            program = build_segment_ir(instructions, self.knowledge)
            lines.append(
                f"; ir segment {segment.index} offset=0x{segment.start:06X} length={segment.length}"
            )
            lines.extend(program.render())
            lines.append("")

        if selection:
            segment_map = {segment.index: segment for segment in container.segments()}
            for index in selection:
                segment = segment_map.get(index)
                if segment is None:
                    continue
                _emit_segment(segment)
        else:
            for segment in container.segments():
                _emit_segment(segment)

        return "\n".join(lines) + "\n"

    def write_ir(
        self,
        container: MbcContainer,
        output_path: Path,
        *,
        segment_indices: Optional[Sequence[int]] = None,
        max_instructions: Optional[int] = None,
    ) -> None:
        """Generate an IR dump and save it to ``output_path``."""

        ir_text = self.generate_ir(
            container,
            segment_indices=segment_indices,
            max_instructions=max_instructions,
        )
        output_path.write_text(ir_text, "utf-8")
